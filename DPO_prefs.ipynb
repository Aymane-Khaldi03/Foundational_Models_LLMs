{"cells":[{"cell_type":"markdown","metadata":{"id":"bqmDP4YympL2"},"source":["# Direct Preference Optimization (DPO) Training\n","\n","## Overview\n","This notebook trains language models using Direct Preference Optimization (DPO).\n","DPO teaches models to prefer better responses over worse ones."]},{"cell_type":"markdown","metadata":{"id":"O-0vIN_empL7"},"source":["## Step 1: Install Required Packages"]},{"cell_type":"code","source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"       # prevent Weights & Biases popups\n","os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""],"metadata":{"id":"rmT4Bi506hgZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import random, numpy as np, torch\n","random.seed(0); np.random.seed(0); torch.manual_seed(0);\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(0)"],"metadata":{"id":"6dUhGv4R6mL1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8kym1AoYmpL9","executionInfo":{"status":"ok","timestamp":1761288285213,"user_tz":300,"elapsed":19048,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"969e4d5a-c8cd-4818-901d-ec0cec7d5b23"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Install all necessary libraries\n","# This may take 2-3 minutes\n","!pip install -q transformers datasets accelerate trl peft bitsandbytes sentencepiece protobuf"]},{"cell_type":"markdown","metadata":{"id":"pr-c1kHvmpMA"},"source":["## Step 2: Import Libraries and Check GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFr54FX8mpMB","executionInfo":{"status":"ok","timestamp":1761288324642,"user_tz":300,"elapsed":39427,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"fc66c073-ef67-49a1-b92d-d894c90fd146"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]},{"output_type":"stream","name":"stdout","text":["device: cuda\n","GPU: Tesla T4\n"]}],"source":["# ---------- Imports ----------\n","from datasets import Dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForCausalLM,\n",")\n","from trl import DPOConfig, DPOTrainer\n","from peft import LoraConfig, get_peft_model\n","\n","# ---------- Device ----------\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"device:\", device)\n","if device == \"cuda\":\n","    print(\"GPU:\", torch.cuda.get_device_name(0))"]},{"cell_type":"markdown","metadata":{"id":"qG5HmVzWmpMC"},"source":["## Step 3: Choose Your Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sw4BgQb0mpMD","executionInfo":{"status":"ok","timestamp":1761288324669,"user_tz":300,"elapsed":29,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"e5fcee91-f3b2-418c-e549-fd93eb30023f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Selected model: HuggingFaceTB/SmolLM2-360M-Instruct\n"]}],"source":["# ============================================\n","# SELECT MODEL\n","# ============================================\n","MODEL_NAME = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n","\n","# (Optional swaps for later, require access and more VRAM)\n","# MODEL_NAME = \"gpt2\"\n","# MODEL_NAME = \"google/gemma-2-2b-it\"\n","# MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n","\n","print(\"Selected model:\", MODEL_NAME)"]},{"cell_type":"markdown","metadata":{"id":"iA3QqxdLmpME"},"source":["## Step 4: Hugging Face Authentication (Only for Gemma/Llama)\n","\n","**Skip this step if using GPT-2**\n","\n","For Gemma or Llama models:\n","1. Go to https://huggingface.co/settings/tokens\n","2. Create a token with read access\n","3. For Llama: Accept the license at https://huggingface.co/meta-llama/Llama-3.2-1B\n","4. For Gemma: Accept the license at https://huggingface.co/google/gemma-2b\n","5. Run the cell below and paste your token"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["374b8f6990d04790a19ebbe691597471","cd81930e981e47c8bc78279fd38e7119","33805240204f4cf98ab25e1579c666f1","9f074049f90e49b9a7e6664c350d58c2","db4430aabacd42c68ac1865a3910574e","ddb26a7ba4a34d0b88b53aac5948c14d","11762d08c85c4da88168b13b199a151c","f7e026f0001246d8962555868959dd9c","da3c9a1f22254075be35ee8ce0d59ccc","a7e9b5b14fcc4ab6b4cd7a057d7700e2","96d44198c09748849f71a63ca15c6e27","dceb008d2e09488986286138c26eb1e7","56b14fadb5c04806b5b6859ac330626e","1613157f27d7477f980e1b48b37b59e8","af023f499cc846b88dc06c8855ea4590","673fa354275447f6a825654385a87855","a683372e89234121be865dc15f2f7bcf"]},"collapsed":true,"id":"fnMYrSt7mpMF","executionInfo":{"status":"ok","timestamp":1760997258545,"user_tz":300,"elapsed":33,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"2fea0883-4030-4dd7-e478-989f248863b3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"374b8f6990d04790a19ebbe691597471"}},"metadata":{}}],"source":["# Only run this cell if using Gemma or Llama models\n","# Comment out if using GPT-2\n","\n","from huggingface_hub import login\n","\n","# Paste your Hugging Face token here or use the popup\n","login()  # This will prompt for your token"]},{"cell_type":"markdown","metadata":{"id":"2get__3YmpMG"},"source":["## Step 5: Create Preference Dataset\n","\n","DPO needs examples of:\n","- **Query**: The question or prompt\n","- **Chosen**: The good/preferred response\n","- **Rejected**: The bad/non-preferred response"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x5X2WOpCmpMH","executionInfo":{"status":"ok","timestamp":1761289842336,"user_tz":300,"elapsed":37,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"a75984ab-ebd2-4e1c-ebb0-d909d06cbb65"},"outputs":[{"output_type":"stream","name":"stdout","text":["Preference pairs: 80\n"]}],"source":["import random\n","random.seed(0)\n","\n","# richer intents + many paraphrases\n","GOOD = {\n","  \"greet\": [\n","    \"Hello! How are you doing today?\",\n","    \"Hi there! It’s nice to meet you.\",\n","    \"Good morning! Hope you’re well.\",\n","    \"Hey! Great to see you.\"\n","  ],\n","  \"thanks\": [\n","    \"Thank you so much for your help!\",\n","    \"I really appreciate your support.\",\n","    \"Thanks a lot—this means a lot to me.\",\n","    \"Many thanks for your assistance!\"\n","  ],\n","  \"goodbye\": [\n","    \"Goodbye! Have a wonderful day!\",\n","    \"See you later—take care!\",\n","    \"Bye for now! Wishing you well.\",\n","    \"Farewell! Hope to see you soon.\"\n","  ],\n","  \"compliment\": [\n","    \"You did an amazing job on this!\",\n","    \"That’s impressive work—well done!\",\n","    \"Fantastic effort—you nailed it!\",\n","    \"Great job! Your work really stands out.\"\n","  ],\n","  \"apology\": [\n","    \"I sincerely apologize for that.\",\n","    \"I’m sorry—I take responsibility.\",\n","    \"My apologies for the mistake.\",\n","    \"I’m truly sorry for the inconvenience.\"\n","  ]\n","}\n","\n","# “hard negatives” = plausible but weaker/flat/abrupt alternatives\n","BAD = {\n","  \"greet\": [\n","    \"Hello.\", \"Hi.\", \"Hey.\", \"Yo.\"\n","  ],\n","  \"thanks\": [\n","    \"Thanks.\", \"Thx.\", \"Ok thanks.\", \"K thx.\"\n","  ],\n","  \"goodbye\": [\n","    \"Bye.\", \"Later.\", \"See ya.\", \"k bye.\"\n","  ],\n","  \"compliment\": [\n","    \"Good work.\", \"Not bad.\", \"Nice.\", \"Decent.\"\n","  ],\n","  \"apology\": [\n","    \"Sorry.\", \"My bad.\", \"Oops.\", \"Whatever, sorry.\"\n","  ]\n","}\n","\n","PROMPTS = {\n","  \"greet\": [\n","    \"How should I greet someone?\",\n","    \"Give me a polite greeting.\",\n","    \"What’s a friendly way to say hello?\",\n","    \"How do I start a conversation nicely?\"\n","  ],\n","  \"thanks\": [\n","    \"How do I say thanks?\",\n","    \"Suggest a polite way to express gratitude.\",\n","    \"Give me a warm thank-you message.\",\n","    \"What’s a heartfelt way to say thank you?\"\n","  ],\n","  \"goodbye\": [\n","    \"How do I say goodbye politely?\",\n","    \"Suggest a friendly farewell.\",\n","    \"What’s a nice way to end a conversation?\",\n","    \"Give me a positive farewell message.\"\n","  ],\n","  \"compliment\": [\n","    \"How do I compliment someone?\",\n","    \"Give me a short, strong compliment.\",\n","    \"Suggest a nice compliment for good work.\",\n","    \"What’s a motivating compliment?\"\n","  ],\n","  \"apology\": [\n","    \"How should I apologize?\",\n","    \"Give me a sincere apology sentence.\",\n","    \"What’s a respectful way to say sorry?\",\n","    \"Suggest a heartfelt apology.\"\n","  ]\n","}\n","\n","rows = []\n","for intent, prompts in PROMPTS.items():\n","    for p in prompts:\n","        for pos in GOOD[intent]:\n","            # pick a *hard* negative close in meaning\n","            neg = random.choice(BAD[intent])\n","            rows.append({\"prompt\": p, \"chosen\": pos, \"rejected\": neg})\n","\n","# optional shuffle + down/up-sample to target size (e.g., ~600 pairs)\n","random.shuffle(rows)\n","rows = rows[:600]\n","\n","train_dataset = Dataset.from_list(rows)\n","print(\"Preference pairs:\", len(train_dataset))\n"]},{"cell_type":"code","source":["# split 90/10\n","split = int(0.9 * len(train_dataset))\n","val_dataset = train_dataset.select(range(split, len(train_dataset)))\n","train_dataset = train_dataset.select(range(split))\n","\n","print(\"Train:\", len(train_dataset), \"Val:\", len(val_dataset))\n","\n","# helper: logprob of sequence under the model\n","import torch\n","from torch.nn.functional import log_softmax\n","\n","@torch.no_grad()\n","def seq_logprob(text):\n","    enc = tokenizer(text, return_tensors=\"pt\").to(model.device)\n","    out = model(**enc, labels=enc.input_ids)\n","    # negative loss is average logprob per token\n","    return -out.loss.item()\n","\n","@torch.no_grad()\n","def dpo_pref_accuracy(dataset, n=50):\n","    # sample n pairs\n","    idxs = list(range(len(dataset)))\n","    random.shuffle(idxs); idxs = idxs[:n]\n","    correct = 0\n","    for i in idxs:\n","        row = dataset[i]\n","        lp_ch = seq_logprob(row[\"prompt\"] + \" \" + row[\"chosen\"])\n","        lp_rj = seq_logprob(row[\"prompt\"] + \" \" + row[\"rejected\"])\n","        if lp_ch > lp_rj:\n","            correct += 1\n","    return correct / max(1, len(idxs))\n","\n","print(\"Pre-train val pref-acc (est):\", dpo_pref_accuracy(val_dataset, n=80))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rc4IFU-UDe1x","executionInfo":{"status":"ok","timestamp":1761289848370,"user_tz":300,"elapsed":2857,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"3313c3cd-111e-4a27-fbc4-0e64daf6221e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"]},{"output_type":"stream","name":"stdout","text":["Train: 72 Val: 8\n","Pre-train val pref-acc (est): 1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZVRgchjNmpMI"},"source":["## Step 6: Load Model and Tokenizer\n","\n","We'll use 4-bit quantization to save memory (allows larger models on free Colab)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUlMlAegmpMJ"},"outputs":[],"source":["from transformers import BitsAndBytesConfig\n","\n","use_4bit = (device == \"cuda\")  # only quantize on GPU\n","quant_cfg = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    bnb_4bit_use_double_quant=True,\n",") if use_4bit else None\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n","# many small models lack pad token; set it safely\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    device_map=\"auto\" if device == \"cuda\" else None,\n","    torch_dtype=torch.bfloat16 if device == \"cuda\" else torch.float32,\n","    quantization_config=quant_cfg,\n","    trust_remote_code=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"YaiOjkhtmpMK"},"source":["## Step 7: Configure LoRA (Low-Rank Adaptation)\n","\n","LoRA allows efficient fine-tuning by only training a small number of parameters.\n","This is essential for free Colab resources."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKf89t6ympML","executionInfo":{"status":"ok","timestamp":1761289858904,"user_tz":300,"elapsed":311,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"3fa4f6b3-864a-4eed-89e2-0a983bbd4ac6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable params: 8,683,520 (4.07% of total)\n"]}],"source":["# For this architecture, these targets are standard. If you switch to GPT-2 later,\n","# you'll need gpt2-specific targets like [\"c_attn\", \"c_proj\"].\n","lora_cfg = LoraConfig(\n","    r=16, lora_alpha=32, lora_dropout=0.05,\n","    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n","    bias=\"none\", task_type=\"CAUSAL_LM\"\n",")\n","model = get_peft_model(model, lora_cfg)\n","trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","total = sum(p.numel() for p in model.parameters())\n","print(f\"Trainable params: {trainable:,} ({100*trainable/total:.2f}% of total)\")\n"]},{"cell_type":"markdown","metadata":{"id":"rskux9PfmpMM"},"source":["## Step 8: Configure DPO Training\n","\n","Set hyperparameters for Direct Preference Optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6RUDvlxOmpMM"},"outputs":[],"source":["cfg = DPOConfig(\n","    output_dir=\"./dpo-output\",\n","    report_to=\"none\",\n","    remove_unused_columns=False,\n","\n","    max_length=256,\n","    max_prompt_length=128,\n","\n","    per_device_train_batch_size=1,\n","    gradient_accumulation_steps=8,   # slightly larger effective batch\n","    num_train_epochs=2,              # fewer epochs to avoid overfitting tiny data\n","    learning_rate=5e-5,\n","    lr_scheduler_type=\"cosine\",\n","    warmup_ratio=0.1,\n","\n","    bf16=(device==\"cuda\"),\n","    gradient_checkpointing=True,\n","    optim=\"paged_adamw_8bit\" if device==\"cuda\" else \"adamw_torch\",\n","    logging_steps=10,\n","    save_strategy=\"epoch\",\n","    save_total_limit=1,\n","\n","    beta=0.2,   # a touch higher than 0.1; try 0.1–0.3 to see effect\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"eZhB35P6mpMN"},"source":["## Step 9: Initialize DPO Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["1c47ca7dc2534f44b682fb43afe43539","27fadcb29d44498c81308fe71af7688a","b9563f4a2a094cb79b987bb4e325b973","f46a647ea5144b47a5d9d78a497a3a20","0da8dd2d8c4a471494c5b13f2a029b65","3e0abbd244f649739eb4ead221080677","d4030a552d064c339334c469146b0438","7c1e90d60eab4b97b0658ddc0ec0758a","242cdf4ee7a540c8b5b1bf60ce39b343","8830b5e7691f46908e4f09cf0b75d65f","42996450d63241f2a474088ffcea2883","4fe2a7b183324848939bd5c3b017eb07","5e59e578c67e44f594602776d1a8a01d","1e601b31a3a743169574fa0f68dc685c","9f4f5056298e4deebed9f6bffb044473","51d31340b0434f9db848ef87f4a38743","78a773df5db34f29a7d613d4acd146b4","00783e6d777f4b4f8f3748bf005448de","932df8d5cb0941a48310f9d875b418e8","3447ee5ce5374b58997c8256f78f2d0c","2052b47c72ce483b81c01c1c22913a37","87632e54fc354848a69423a5af417272","83b7c32371564c1fa6c4f7b3388de28d","0e0e955d70b2424fa5d2547395c516f4","830cbbbbe7584d9bb24c5545ac04c9e4","a8e21587945440b9bab7343ed6950694","0785b920b20743aaaa7e62cdb0b9341e","4406883d07584f01bc95e017f43310e2","ea9026698aae41b9818016a0ad863d59","6c7e0e47239e448694c43a38469f73bc","babf1e1df51c4e7c80a881b8f63da545","2834bd1d1a64434b83da2d7c98564dc3","68995ee648374fd890c65370cb3b2cc7"]},"id":"9G1sCFW1mpMO","executionInfo":{"status":"ok","timestamp":1761289867053,"user_tz":300,"elapsed":1032,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"b7f8cbec-8f9e-4bf2-dbea-74bdb6e64577"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Extracting prompt in train dataset:   0%|          | 0/72 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c47ca7dc2534f44b682fb43afe43539"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Applying chat template to train dataset:   0%|          | 0/72 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fe2a7b183324848939bd5c3b017eb07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Tokenizing train dataset:   0%|          | 0/72 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b7c32371564c1fa6c4f7b3388de28d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DPO trainer ready.\n"]}],"source":["trainer = DPOTrainer(\n","    model=model,\n","    args=cfg,\n","    train_dataset=train_dataset,\n",")\n","print(\"DPO trainer ready.\")"]},{"cell_type":"markdown","metadata":{"id":"R2ttKgwqmpMP"},"source":["## Step 10: Train the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"id":"4tjun-QNmpMP","executionInfo":{"status":"ok","timestamp":1761289978568,"user_tz":300,"elapsed":108692,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"1d27080d-19dc-406e-86c9-edae975d3d27"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting DPO training...\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [18/18 01:42, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.673200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"]},{"output_type":"stream","name":"stdout","text":["\n","✓ Training completed!\n"]}],"source":["# Start training\n","print(\"Starting DPO training...\\n\")\n","trainer.train()\n","print(\"\\n✓ Training completed!\")"]},{"cell_type":"code","source":["print(\"Post-train val pref-acc (est):\", dpo_pref_accuracy(val_dataset, n=80))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3KueKBdrDg-Z","executionInfo":{"status":"ok","timestamp":1761289991561,"user_tz":300,"elapsed":2877,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"04f409ee-9500-4435-ac1b-735c9250227e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Post-train val pref-acc (est): 1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"FkaDX9VfmpMQ"},"source":["## Step 11: Save the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5rvA0kSmpMR","executionInfo":{"status":"ok","timestamp":1761290000956,"user_tz":300,"elapsed":394,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"aac2c23b-a55b-4e90-8090-75b39555d4be"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Model saved to: ./dpo-finetuned-model\n"]}],"source":["# Save model and tokenizer\n","output_dir = \"./dpo-finetuned-model\"\n","trainer.save_model(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","print(f\"✓ Model saved to: {output_dir}\")"]},{"cell_type":"markdown","metadata":{"id":"dXD2o4TGmpMR"},"source":["## Step 12: Test the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jm6KtJI9mpMS","executionInfo":{"status":"ok","timestamp":1761290546544,"user_tz":300,"elapsed":20433,"user":{"displayName":"Aymane Khaldi","userId":"17145091476254487286"}},"outputId":"d5d1fbd6-e862-4a40-c755-bc93551a6b2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== DPO Model Samples ===\n","Q: Give me a polite greeting.\n","A: Hello, I'm happy to be your guide today. I'm here to assist you in navigating the world of data analysis and machine learning. I'm\n","--------------------------------------------------\n","Q: What’s a heartfelt way to say thank you?\n","A: \"Thank you for your kind words and gestures. I hope you have a wonderful day ahead.\"\n","--------------------------------------------------\n","Q: Suggest a friendly farewell.\n","A: \"Goodbye, and may the day be filled with love and joy!\"\n","--------------------------------------------------\n","Q: Give me a short, strong compliment.\n","A: \"You're a great person, and you're always willing to help others.\"\n","--------------------------------------------------\n","Q: How should I apologize sincerely?\n","A: Apologizing sincerely is a crucial part of maintaining a positive relationship. It shows that you care about the other person's feelings and are willing to make\n","--------------------------------------------------\n"]}],"source":["def generate_response(prompt, max_new_tokens=30, temperature=0.0):\n","    \"\"\"\n","    For instruct models with a chat template (e.g., SmolLM2 Instruct), we format\n","    the prompt accordingly. We default to deterministic decoding (temperature=0.0)\n","    to avoid gibberish in a classroom demo.\n","    \"\"\"\n","    if hasattr(tokenizer, \"apply_chat_template\") and tokenizer.chat_template:\n","        messages = [{\"role\": \"user\", \"content\": prompt}]\n","        text = tokenizer.apply_chat_template(\n","            messages, tokenize=False, add_generation_prompt=True\n","        )\n","    else:\n","        # Fallback for plain causal models (e.g., gpt2)\n","        text = prompt\n","\n","    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n","    out = model.generate(\n","        **inputs,\n","        max_new_tokens=max_new_tokens,\n","        do_sample=(temperature > 0.0),\n","        temperature=max(temperature, 1e-6),\n","        top_p=0.9,\n","        pad_token_id=tokenizer.pad_token_id,\n","        eos_token_id=tokenizer.eos_token_id,\n","    )\n","    # Slice off the prompt tokens properly (use input length, not len(inputs[0]))\n","    gen_tokens = out[0, inputs.input_ids.shape[1]:]\n","    return tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n","\n","# ---------- Quick test on a few prompts ----------\n","test_prompts = [\n","    \"Give me a polite greeting.\",\n","    \"What’s a heartfelt way to say thank you?\",\n","    \"Suggest a friendly farewell.\",\n","    \"Give me a short, strong compliment.\",\n","    \"How should I apologize sincerely?\"\n","]\n","# We Disable gradient checkpointing before generation\n","model.gradient_checkpointing_disable()\n","model.eval()\n","\n","print(\"\\n=== DPO Model Samples ===\")\n","for q in test_prompts:\n","    print(\"Q:\", q)\n","    print(\"A:\", generate_response(q))\n","    print(\"-\"*50)"]},{"cell_type":"code","source":[],"metadata":{"id":"58E3lhXgn7Q3"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"374b8f6990d04790a19ebbe691597471":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_cd81930e981e47c8bc78279fd38e7119","IPY_MODEL_33805240204f4cf98ab25e1579c666f1","IPY_MODEL_9f074049f90e49b9a7e6664c350d58c2","IPY_MODEL_db4430aabacd42c68ac1865a3910574e","IPY_MODEL_ddb26a7ba4a34d0b88b53aac5948c14d"],"layout":"IPY_MODEL_11762d08c85c4da88168b13b199a151c"}},"cd81930e981e47c8bc78279fd38e7119":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7e026f0001246d8962555868959dd9c","placeholder":"​","style":"IPY_MODEL_da3c9a1f22254075be35ee8ce0d59ccc","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"33805240204f4cf98ab25e1579c666f1":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_a7e9b5b14fcc4ab6b4cd7a057d7700e2","placeholder":"​","style":"IPY_MODEL_96d44198c09748849f71a63ca15c6e27","value":""}},"9f074049f90e49b9a7e6664c350d58c2":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_dceb008d2e09488986286138c26eb1e7","style":"IPY_MODEL_56b14fadb5c04806b5b6859ac330626e","value":true}},"db4430aabacd42c68ac1865a3910574e":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_1613157f27d7477f980e1b48b37b59e8","style":"IPY_MODEL_af023f499cc846b88dc06c8855ea4590","tooltip":""}},"ddb26a7ba4a34d0b88b53aac5948c14d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_673fa354275447f6a825654385a87855","placeholder":"​","style":"IPY_MODEL_a683372e89234121be865dc15f2f7bcf","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"11762d08c85c4da88168b13b199a151c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"f7e026f0001246d8962555868959dd9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da3c9a1f22254075be35ee8ce0d59ccc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7e9b5b14fcc4ab6b4cd7a057d7700e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d44198c09748849f71a63ca15c6e27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dceb008d2e09488986286138c26eb1e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56b14fadb5c04806b5b6859ac330626e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1613157f27d7477f980e1b48b37b59e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af023f499cc846b88dc06c8855ea4590":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"673fa354275447f6a825654385a87855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a683372e89234121be865dc15f2f7bcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c47ca7dc2534f44b682fb43afe43539":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27fadcb29d44498c81308fe71af7688a","IPY_MODEL_b9563f4a2a094cb79b987bb4e325b973","IPY_MODEL_f46a647ea5144b47a5d9d78a497a3a20"],"layout":"IPY_MODEL_0da8dd2d8c4a471494c5b13f2a029b65"}},"27fadcb29d44498c81308fe71af7688a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e0abbd244f649739eb4ead221080677","placeholder":"​","style":"IPY_MODEL_d4030a552d064c339334c469146b0438","value":"Extracting prompt in train dataset: 100%"}},"b9563f4a2a094cb79b987bb4e325b973":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c1e90d60eab4b97b0658ddc0ec0758a","max":72,"min":0,"orientation":"horizontal","style":"IPY_MODEL_242cdf4ee7a540c8b5b1bf60ce39b343","value":72}},"f46a647ea5144b47a5d9d78a497a3a20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8830b5e7691f46908e4f09cf0b75d65f","placeholder":"​","style":"IPY_MODEL_42996450d63241f2a474088ffcea2883","value":" 72/72 [00:00&lt;00:00, 2555.92 examples/s]"}},"0da8dd2d8c4a471494c5b13f2a029b65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e0abbd244f649739eb4ead221080677":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4030a552d064c339334c469146b0438":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c1e90d60eab4b97b0658ddc0ec0758a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"242cdf4ee7a540c8b5b1bf60ce39b343":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8830b5e7691f46908e4f09cf0b75d65f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42996450d63241f2a474088ffcea2883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fe2a7b183324848939bd5c3b017eb07":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e59e578c67e44f594602776d1a8a01d","IPY_MODEL_1e601b31a3a743169574fa0f68dc685c","IPY_MODEL_9f4f5056298e4deebed9f6bffb044473"],"layout":"IPY_MODEL_51d31340b0434f9db848ef87f4a38743"}},"5e59e578c67e44f594602776d1a8a01d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78a773df5db34f29a7d613d4acd146b4","placeholder":"​","style":"IPY_MODEL_00783e6d777f4b4f8f3748bf005448de","value":"Applying chat template to train dataset: 100%"}},"1e601b31a3a743169574fa0f68dc685c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_932df8d5cb0941a48310f9d875b418e8","max":72,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3447ee5ce5374b58997c8256f78f2d0c","value":72}},"9f4f5056298e4deebed9f6bffb044473":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2052b47c72ce483b81c01c1c22913a37","placeholder":"​","style":"IPY_MODEL_87632e54fc354848a69423a5af417272","value":" 72/72 [00:00&lt;00:00, 2651.17 examples/s]"}},"51d31340b0434f9db848ef87f4a38743":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78a773df5db34f29a7d613d4acd146b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00783e6d777f4b4f8f3748bf005448de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"932df8d5cb0941a48310f9d875b418e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3447ee5ce5374b58997c8256f78f2d0c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2052b47c72ce483b81c01c1c22913a37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87632e54fc354848a69423a5af417272":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83b7c32371564c1fa6c4f7b3388de28d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e0e955d70b2424fa5d2547395c516f4","IPY_MODEL_830cbbbbe7584d9bb24c5545ac04c9e4","IPY_MODEL_a8e21587945440b9bab7343ed6950694"],"layout":"IPY_MODEL_0785b920b20743aaaa7e62cdb0b9341e"}},"0e0e955d70b2424fa5d2547395c516f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4406883d07584f01bc95e017f43310e2","placeholder":"​","style":"IPY_MODEL_ea9026698aae41b9818016a0ad863d59","value":"Tokenizing train dataset: 100%"}},"830cbbbbe7584d9bb24c5545ac04c9e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c7e0e47239e448694c43a38469f73bc","max":72,"min":0,"orientation":"horizontal","style":"IPY_MODEL_babf1e1df51c4e7c80a881b8f63da545","value":72}},"a8e21587945440b9bab7343ed6950694":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2834bd1d1a64434b83da2d7c98564dc3","placeholder":"​","style":"IPY_MODEL_68995ee648374fd890c65370cb3b2cc7","value":" 72/72 [00:00&lt;00:00, 1268.58 examples/s]"}},"0785b920b20743aaaa7e62cdb0b9341e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4406883d07584f01bc95e017f43310e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea9026698aae41b9818016a0ad863d59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c7e0e47239e448694c43a38469f73bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"babf1e1df51c4e7c80a881b8f63da545":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2834bd1d1a64434b83da2d7c98564dc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68995ee648374fd890c65370cb3b2cc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}