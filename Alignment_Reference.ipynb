{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYaYft5w2Ako"
   },
   "source": [
    "# Alignment Using Preference Dataset\n",
    "\n",
    "## Overview\n",
    "This notebook shows how to fine-tune a language model using **Supervised Fine-Tuning (SFT)**.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Create a dataset with multiple outputs per instruction (some good, some bad)\n",
    "- Train the model using ONLY the good (accepted) examples\n",
    "- Test the aligned model on new questions\n",
    "\n",
    "**Key concept:** The model learns \"what good responses look like\" by training on accepted examples only. Bad examples are stored for future use with DPO (a more advanced technique)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFDmB5tY2GLP"
   },
   "source": [
    "## Step 1: Install Libraries\n",
    "\n",
    "Install packages needed for model training, LoRA fine-tuning, and quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17057,
     "status": "ok",
     "timestamp": 1762380442069,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 360
    },
    "id": "yMumCzDP0rgo",
    "outputId": "cca52fee-b425-406e-e8b9-ce1810e0df17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries installed\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch accelerate peft bitsandbytes trl -q\n",
    "\n",
    "print(\"✓ Libraries installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPbJMnz62LQG"
   },
   "source": [
    "## Step 2: Import Libraries\n",
    "\n",
    "Import everything we need for model loading, training, and fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51941,
     "status": "ok",
     "timestamp": 1762380494012,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 360
    },
    "id": "YhaX2mJT2JZM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU Availability\n",
    "\n",
    "Verify that we have access to a GPU for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1762380494031,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 360
    },
    "id": "i4UM9-W42Rk8",
    "outputId": "69af0e1b-db45-41d2-c915-0e8ebd4ee421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla T4\n",
      "CUDA Available: True\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1o4wDJpD2QGy"
   },
   "source": [
    "## Step 3: Create Preference Dataset\n",
    "\n",
    "**Format:** Each instruction has 3-4 possible responses. Each response is labeled:\n",
    "- **\"accepted\"** = Good, high-quality response\n",
    "- **\"rejected\"** = Poor or unhelpful response\n",
    "\n",
    "**Important:** SFT training uses ONLY accepted examples. Rejected ones are saved for DPO (a different training method that learns from comparisons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1762380494035,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 360
    },
    "id": "GUeZpUrg2Pjv",
    "outputId": "1bc9b0a7-ff3d-480a-bc64-d2975dd646ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created dataset with 8 instructions\n",
      "  Each instruction has multiple outputs (accepted/rejected)\n",
      "\n",
      "Example structure:\n",
      "Instruction: Explain photosynthesis to a 10-year-old.\n",
      "Number of outputs: 4\n",
      "  Output 1: accepted - Photosynthesis is how plants make their own food! Plants use...\n",
      "  Output 2: rejected - Photosynthesis is a biological process involving light-depen...\n",
      "  Output 3: rejected - Plants eat sunlight....\n",
      "  Output 4: accepted - Think of plants as having tiny solar panels in their leaves!...\n"
     ]
    }
   ],
   "source": [
    "preference_data = [\n",
    "    {\n",
    "        \"instruction\": \"Explain photosynthesis to a 10-year-old.\",\n",
    "        \"outputs\": [\n",
    "            {\"text\": \"Photosynthesis is how plants make their own food! Plants use sunlight, water from the soil, and air to create energy. The green color in leaves (called chlorophyll) helps catch the sunlight. It's like plants are cooking their own meal using sunshine as the heat source!\", \"label\": \"accepted\"},\n",
    "            {\"text\": \"Photosynthesis is a biological process involving light-dependent and light-independent reactions where chloroplasts convert electromagnetic radiation into chemical energy through the Calvin cycle.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Plants eat sunlight.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Think of plants as having tiny solar panels in their leaves! They use sunlight, water, and carbon dioxide from air to make sugar (their food) and release oxygen that we breathe. The green chlorophyll is like the solar panel that captures the sun's energy.\", \"label\": \"accepted\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Write a professional email declining a job offer.\",\n",
    "        \"outputs\": [\n",
    "            {\"text\": \"Dear [Hiring Manager],\\n\\nThank you so much for offering me the [Position] role at [Company]. I truly appreciate the time you and your team invested in the interview process.\\n\\nAfter careful consideration, I have decided to decline the offer as I've accepted a position that better aligns with my career goals.\\n\\nI was impressed by [Company] and hope our paths cross again in the future.\\n\\nBest regards,\\n[Your Name]\", \"label\": \"accepted\"},\n",
    "            {\"text\": \"No thanks, I found something better.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"I'm not interested in working for your company anymore. Thanks anyway.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Dear [Hiring Manager],\\n\\nI want to express my gratitude for the [Position] offer at [Company]. The opportunity was compelling and the interview process was very positive.\\n\\nHowever, after thoughtful consideration, I've decided to pursue another opportunity that aligns more closely with my long-term career objectives.\\n\\nI hold [Company] in high regard and would welcome the chance to connect in the future.\\n\\nSincerely,\\n[Your Name]\", \"label\": \"accepted\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Explain the difference between machine learning and deep learning.\",\n",
    "        \"outputs\": [\n",
    "            {\"text\": \"Machine Learning (ML) is a broad field where computers learn patterns from data. Deep Learning (DL) is a subset of ML that uses neural networks with many layers (hence 'deep'). Think of ML as a toolbox with many tools, and DL as one powerful tool in that box. DL excels at complex tasks like image recognition and language understanding.\", \"label\": \"accepted\"},\n",
    "            {\"text\": \"They're basically the same thing.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Deep learning uses more GPUs than machine learning.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Machine Learning encompasses various algorithms that learn from data, including decision trees, SVMs, and neural networks. Deep Learning specifically refers to neural networks with multiple hidden layers (2+), enabling hierarchical feature learning. While ML may require manual feature engineering, DL automatically learns features from raw data.\", \"label\": \"accepted\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Give three tips for effective time management.\",\n",
    "        \"outputs\": [\n",
    "            {\"text\": \"1. **Prioritize tasks**: Use the Eisenhower Matrix to separate urgent vs. important tasks. Focus on what matters most.\\n\\n2. **Time blocking**: Dedicate specific time slots to specific activities. This reduces decision fatigue and increases focus.\\n\\n3. **Eliminate distractions**: Turn off notifications during deep work sessions. Your phone and social media will still be there later.\", \"label\": \"accepted\"},\n",
    "            {\"text\": \"Work harder, sleep less, multitask always.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Just make a to-do list.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"1. **Set clear priorities**: Identify your most important tasks each day using methods like the 80/20 rule. Complete high-impact work first.\\n\\n2. **Use time blocking**: Schedule specific blocks for focused work, meetings, and breaks. Treat these blocks as non-negotiable appointments.\\n\\n3. **Minimize context switching**: Group similar tasks together and eliminate interruptions during deep work periods.\", \"label\": \"accepted\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"What should I do if my laptop won't turn on?\",\n",
    "        \"outputs\": [\n",
    "            {\"text\": \"Try these troubleshooting steps:\\n\\n1. Check if it's charged: Plug in the charger and wait 15 minutes, then try again.\\n\\n2. Hard reset: Hold the power button for 30 seconds, release, then press it normally.\\n\\n3. Remove peripherals: Disconnect all USB devices, external monitors, etc., then try starting.\\n\\n4. If still not working, the battery or power adapter might be faulty. Consider taking it to a technician.\", \"label\": \"accepted\"},\n",
    "            {\"text\": \"Buy a new laptop.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Have you tried turning it off and on again?\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"First, ensure the power adapter is connected and the outlet works. Wait 15-20 minutes for charging. Next, perform a hard reset by holding the power button for 30 seconds. Remove all external devices and try booting. If unsuccessful, test with a different charger if available, or consult a repair technician.\", \"label\": \"accepted\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"How do I start learning Python programming?\",\n",
    "        \"outputs\": [\n",
    "            {\"text\": \"Here's a beginner-friendly roadmap:\\n\\n1. **Install Python**: Download from python.org or use Google Colab (online, free).\\n\\n2. **Learn basics**: Variables, data types, loops, and functions. Use free resources like Python.org tutorials or freeCodeCamp.\\n\\n3. **Practice daily**: Solve problems on sites like HackerRank or LeetCode (easy level).\\n\\n4. **Build projects**: Start small (calculator, to-do list) then progress to larger projects.\\n\\n5. **Join communities**: Reddit's r/learnpython and Python Discord are great for questions.\", \"label\": \"accepted\"},\n",
    "            {\"text\": \"Just watch YouTube videos.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Python is easy, you don't need to study much.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Begin by setting up Python (python.org or Anaconda). Master fundamentals: variables, control flow, functions, and data structures. Practice through coding challenges on platforms like Codewars or HackerRank. Build simple projects (web scraper, automation script) to apply knowledge. Engage with learning communities and read documentation regularly.\", \"label\": \"accepted\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Summarize the plot of Romeo and Juliet in 2 sentences.\",\n",
    "        \"outputs\": [\n",
    "            {\"text\": \"Romeo and Juliet are young lovers from two feuding families in Verona, Italy. Despite their families' hatred, they secretly marry, but a series of misunderstandings leads to both their tragic deaths, which finally reconciles the families.\", \"label\": \"accepted\"},\n",
    "            {\"text\": \"It's a love story where everyone dies.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Romeo and Juliet fall in love and then there's some drama.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Two teenagers from rival families in Verona fall in love and marry secretly. A tragic chain of events involving miscommunication and impulsive decisions results in both their deaths, ultimately ending the family feud.\", \"label\": \"accepted\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"What are the health benefits of drinking water?\",\n",
    "        \"outputs\": [\n",
    "            {\"text\": \"Drinking adequate water provides numerous health benefits: It regulates body temperature, lubricates joints, helps deliver nutrients to cells, and keeps organs functioning properly. Water also improves skin health, aids digestion, helps with weight management, and prevents dehydration which can cause fatigue and headaches. Aim for 8 glasses (64 oz) per day, more if you're active.\", \"label\": \"accepted\"},\n",
    "            {\"text\": \"Water is good for you.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"It makes you not thirsty.\", \"label\": \"rejected\"},\n",
    "            {\"text\": \"Water is essential for optimal health: it maintains body temperature, supports joint lubrication, facilitates nutrient transport, and ensures proper organ function. Additionally, adequate hydration improves cognitive function, supports metabolism, enhances skin elasticity, aids digestion, and prevents dehydration-related symptoms like headaches and fatigue. Target 8-10 glasses daily.\", \"label\": \"accepted\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"✓ Created dataset with {len(preference_data)} instructions\")\n",
    "print(f\"  Each instruction has multiple outputs (accepted/rejected)\")\n",
    "print(f\"\\nExample structure:\")\n",
    "print(f\"Instruction: {preference_data[0]['instruction']}\")\n",
    "print(f\"Number of outputs: {len(preference_data[0]['outputs'])}\")\n",
    "for i, output in enumerate(preference_data[0]['outputs']):\n",
    "    print(f\"  Output {i+1}: {output['label']} - {output['text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxISdeL52ejf"
   },
   "source": [
    "## Step 4: Extract Accepted Examples\n",
    "\n",
    "Filter the dataset to keep only \"accepted\" responses for training. This is the key to SFT: we only train on high-quality examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training dataset: 80 examples\n",
      "  Using only 'accepted' outputs for training\n",
      "\n",
      "Sample:\n",
      "Instruction: Explain photosynthesis to a 10-year-old.\n",
      "Output: Photosynthesis is how plants make their own food! Plants use sunlight, water from the soil, and air ...\n"
     ]
    }
   ],
   "source": [
    "# Extract only the accepted (good) examples\n",
    "# Why? SFT learns by mimicking good examples. Bad examples would confuse it.\n",
    "training_data = []\n",
    "for item in preference_data:\n",
    "    instruction = item[\"instruction\"]\n",
    "    for output in item[\"outputs\"]:\n",
    "        if output[\"label\"] == \"accepted\":\n",
    "            training_data.append({\n",
    "                \"instruction\": instruction,\n",
    "                \"output\": output[\"text\"]\n",
    "            })\n",
    "\n",
    "# Repeat examples 5x to have more training data\n",
    "training_data = training_data * 5\n",
    "\n",
    "dataset = Dataset.from_list(training_data)\n",
    "\n",
    "print(f\"✓ Training dataset: {len(dataset)} examples\")\n",
    "\n",
    "print(f\"  Using only 'accepted' outputs for training\")\n",
    "print(f\"Output: {dataset[0]['output'][:100]}...\")\n",
    "\n",
    "print(f\"\\nSample:\")\n",
    "print(f\"Instruction: {dataset[0]['instruction']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Load Model\n",
    "\n",
    "Load TinyLlama model with 4-bit quantization to save memory. Quantization reduces memory usage by approximately 75% while maintaining model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TinyLlama/TinyLlama-1.1B-Chat-v1.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84bbe241e534c3a856c309d7449f66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506e84b7c1bf4ce9b34b1ef578c694c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf7740bf9a241ec8cda8c56cce1d278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "max_seq_length = 2048\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "\n",
    "# Configure 4-bit quantization (reduces memory by ~75%)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"✓ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Setup Tokenizer\n",
    "\n",
    "Load and configure the tokenizer. The tokenizer converts text to numbers that the model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1762380667040,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 360
    },
    "id": "cQfdqgDF7W7C",
    "outputId": "7d82ada6-ecd9-4a97-b6a9-1f33aee3c5c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tokenizer configured\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.truncation_side = \"right\"\n",
    "\n",
    "# Set special tokens if missing\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "if tokenizer.bos_token is None:\n",
    "    tokenizer.add_special_tokens({'bos_token': '<s>'})\n",
    "\n",
    "if tokenizer.eos_token is None:\n",
    "    tokenizer.add_special_tokens({'eos_token': '</s>'})\n",
    "\n",
    "print(\"✓ Tokenizer configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pOtb9iW2tn6"
   },
   "source": [
    "## Step 7: Add LoRA Adapters\n",
    "\n",
    "**LoRA** = Efficient training method that only trains 1-2% of model parameters.\n",
    "\n",
    "Benefits: Much faster, uses less memory, same quality as full training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1761287702757,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 300
    },
    "id": "-wlRjmhs2nv6",
    "outputId": "ae33e950-0fe7-4750-ac32-362f3ca0ea7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LoRA adapters added\n",
      "  Trainable: 12,615,680 (2.01%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare model for efficient training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Configure LoRA settings\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # LoRA rank\n",
    "    lora_alpha=32,  # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# Add LoRA adapters to the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Show how many parameters we're actually training\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"  Trainable: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"✓ LoRA adapters added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQlPS3qz205k"
   },
   "source": [
    "## Step 8: Format Dataset\n",
    "\n",
    "Convert data to chat format that the model understands. This applies the model's conversation template to each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "2570369609e24de7a00f2fecc73c4dd5",
      "9d62f4da090a4c6cbe658f232d7737c9",
      "fb9c4a6d51334229a6b84f0279183d1b",
      "edad7a92c5c9479d97d3fffb81e15732",
      "2706a6114e894ef69d809ba8aafa0a87",
      "b5935da2e2da4706ba1ef9cbac5178e0",
      "8bd2cbb574474968888fd6d462677b80",
      "e4582a33049b4cfeac2e2d44b8d77918",
      "5ee046befcb846eeb688c89173b36dc3",
      "26aad99469e44acf8f8e23237d8b3c27",
      "693fb29a51a6487fac68328fcc9138ab"
     ]
    },
    "executionInfo": {
     "elapsed": 88,
     "status": "ok",
     "timestamp": 1761287706937,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 300
    },
    "id": "FpP-pD0a2z-K",
    "outputId": "e9099854-ad27-4d95-d0de-fc1c818306a4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca3b025665942b9b7d9eb2ba243c6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset formatted\n",
      "Sample: <|user|>\n",
      "Explain photosynthesis to a 10-year-old.</s>\n",
      "<|assistant|>\n",
      "Photosynthesis is how plants make their own food! Plants use sunlight, water from ...\n"
     ]
    }
   ],
   "source": [
    "# Format each example as a conversation\n",
    "def format_prompts(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        # Create user-assistant conversation\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": instruction},\n",
    "            {\"role\": \"assistant\", \"content\": output},\n",
    "        ]\n",
    "        # Apply model's chat template\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        texts.append(text)\n",
    "\n",
    "    return {\"text\": texts}\n",
    "\n",
    "# Apply formatting to all examples\n",
    "\n",
    "dataset = dataset.map(format_prompts, batched=True)print(f\"Sample: {dataset[0]['text'][:150]}...\")\n",
    "\n",
    "print(\"✓ Dataset formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucCLRNC027_o"
   },
   "source": [
    "## Step 9: Configure Training\n",
    "\n",
    "Set up training parameters. We'll train for 3 epochs with a small batch size and use mixed precision for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234,
     "referenced_widgets": [
      "9062fe4e3f2342d68e6c6e9ba7706da1",
      "7d6a67c8197841f09795ce3a6b7359e6",
      "954a57e6e67a4d11a25f114ee6eb27d9",
      "a6990773569a4db9bad3509fac8ddc16",
      "17f0dd3348e14f9aaefbbc9a27363b48",
      "649d008043e44b5bacec72411f27de22",
      "ae0c23f370db43358eda4860e7684512",
      "948abb7b38824b57960c69dfd928ba7c",
      "f2bb793078094f1d8fc11aa5e4a9dda1",
      "7e89cf2ccc9f41f5a6c1a254cf0190f2",
      "368e1dd8fe7b4fbb84d8773f4870d817",
      "bb13a1c56bd14d53a7d26e421e27c7bc",
      "7ddacb75e23a48aba945dfea791c39c5",
      "6fd56890138c475f958ca31afdfb897a",
      "ae12386a9fce40808c20cdd436bfe031",
      "52364866254e400fac347c8e75524128",
      "d166381b69fc46e29b70714cddfe3448",
      "24b8e34e1e704d33866bfd8c0e03ae77",
      "a887fa901ce449e49d214b75183f1f6a",
      "913c04cf88084e89bcc42e509c6892c1",
      "9f28ee892b224c27a0f8655f45fe4085",
      "a4a89ff0807a4dd1b5b615c762a518e8",
      "bc7a69e21bcd43e580c9a6e78fdfd172",
      "1f552945661943529cb665cf211e659c",
      "98cb1e3db5bd45b2884857a058610dbc",
      "59db73cff5e045a5b21fbd9c2371e1d0",
      "256000d4e6074d279bf3c2ea5f0a38c0",
      "10a365e1e883499ab23cc7d9b639adb6",
      "75122a9707544360b04bd3c9596d1837",
      "5eee9d4b99264c7b98b5d78094abce8f",
      "3d971d513082457daa995b88f8426b67",
      "e44d001042a6468181aacd9b6ff8dd77",
      "a6a02b2d2a4c48228c5ca98cf02d778c"
     ]
    },
    "executionInfo": {
     "elapsed": 1055,
     "status": "ok",
     "timestamp": 1761287713264,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 300
    },
    "id": "H-D-peC-26Ih",
    "outputId": "f080bf03-d1c0-45d5-e19d-79a8044c8442"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ab74118b8c4c69b0cb5d2a015834d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9186ce7b70384f6db76bcbb3141e4eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eebcf88801143a7a07f456bf0136417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trainer configured\n",
      "  Training for 3 epochs\n",
      "  Batch size: 2\n",
      "  Learning rate: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,  # Train for 3 passes through data\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,  # Use mixed precision for speed\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    warmup_steps=10,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    processing_class=tokenizer\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer configured\")\n",
    "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")print(f\"  Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwUTGAqY3IeL"
   },
   "source": [
    "## Step 10: Train the Model\n",
    "\n",
    "Start training! The model learns from accepted examples only. This typically takes 10-15 minutes on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "executionInfo": {
     "elapsed": 90410,
     "status": "ok",
     "timestamp": 1761287810093,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 300
    },
    "id": "gHP7E84t3Gsc",
    "outputId": "d58ca6bb-ed46-4a5c-f7b3-130baf018478"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Dataset size: 80 examples\n",
      "This will take 10-15 minutes on GPU\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.848300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.355600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Training complete!\n",
      "  Model learned from 80 accepted examples\n",
      "  Rejected examples were used to create contrast in dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "print(f\"Training on {len(dataset)} examples\")\n",
    "print(\"This takes ~10-15 minutes on GPU\\n\")\n",
    "\n",
    "# Run training\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n✓ Training complete!\")\n",
    "print(f\"  Model learned from {len(dataset)} accepted examples\")\n",
    "print(f\"  Note: Rejected examples were NOT used (SFT only learns from good examples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpmZfZmf3Nug"
   },
   "source": [
    "## Step 11: Save Model\n",
    "\n",
    "Save the trained LoRA adapters. The base model stays unchanged - only the small adapter weights are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1761287817173,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 300
    },
    "id": "3pHnmn4_3P7x",
    "outputId": "5fb032e1-0d73-4aa8-c186-579b20af42ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model saved to 'aligned_model'\n",
      "  Files: adapter_config.json, adapter_model.bin, tokenizer\n"
     ]
    }
   ],
   "source": [
    "# Save LoRA adapters and tokenizer\n",
    "model.save_pretrained(\"aligned_model\")\n",
    "tokenizer.save_pretrained(\"aligned_model\")\n",
    "\n",
    "print(\"✓ Model saved to 'aligned_model' folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDc6kseL3RQI"
   },
   "source": [
    "## Step 12: Test the Model\n",
    "\n",
    "Test the trained model on new questions to see if it learned to generate high-quality responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33546,
     "status": "ok",
     "timestamp": 1761287852313,
     "user": {
      "displayName": "Aymane Khaldi",
      "userId": "17145091476254487286"
     },
     "user_tz": 300
    },
    "id": "dUM-6qgO3Tw5",
    "outputId": "2aa10a8d-ec22-420a-9107-1ac5c4448d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing aligned model:\n",
      "\n",
      "Q: How do I make a good first impression?\n",
      "A: |>\n",
      "Here are 8 effective strategies:\n",
      "\n",
      "1. Bring a handmade gift or treats.\n",
      "2. Smile and say hello.\n",
      "3. Prepare a quick introduction: \"Hi, my name is [Name], I'm [Position] at [Company].\"\n",
      "4. Ask open-ended questions to learn more about the role.\n",
      "5. Demonstrate technical skills through simple tasks.\n",
      "6. Focus on common interests and common ground.\n",
      "7. Practice active listening and respond appropriately.\n",
      "8. Leave a positive impression with follow-up messages or thank-you notes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: Explain what DNA is to a child.\n",
      "A: |>\n",
      "Here are 8 effective strategies:\n",
      "\n",
      "1. Bring a handmade gift or treats.\n",
      "2. Smile and say hello.\n",
      "3. Prepare a quick introduction: \"Hi, my name is [Name], I'm [Position] at [Company].\"\n",
      "4. Ask open-ended questions to learn more about the role.\n",
      "5. Demonstrate technical skills through simple tasks.\n",
      "6. Focus on common interests and common ground.\n",
      "7. Practice active listening and respond appropriately.\n",
      "8. Leave a positive impression with follow-up messages or thank-you notes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: Explain what DNA is to a child.\n",
      "A: |>\n",
      "DNA (Deoxyribonucleic acid) is a molecule made up of DNA strands that hold genetic information for each cell in your body. It has helix-like structure and is composed of nucleotides (A, T, C, G) that bind to each other through hydrogen bonding.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: Give tips for staying motivated.\n",
      "A: |>\n",
      "DNA (Deoxyribonucleic acid) is a molecule made up of DNA strands that hold genetic information for each cell in your body. It has helix-like structure and is composed of nucleotides (A, T, C, G) that bind to each other through hydrogen bonding.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: Give tips for staying motivated.\n",
      "A: |>\n",
      "1. Set clear goals: Know what you want to achieve and break it down into achievable steps.\n",
      "\n",
      "2. Find what motivates you: Identify your personal strengths and pursue activities that bring you joy.\n",
      "\n",
      "3. Track progress: Use metrics like time spent on tasks or progress toward your goals to stay focused.\n",
      "\n",
      "4. Connect with others: Social support networks can increase motivation and provide accountability.\n",
      "\n",
      "5. Reward yourself: Treat yourself to something you enjoy after specific milestones or achievements.\n",
      "\n",
      "6. Eliminate distractions: Turn off notifications during focused work sessions.\n",
      "\n",
      "7. Practice self-care: Engage in activities that promote relax\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "A: |>\n",
      "1. Set clear goals: Know what you want to achieve and break it down into achievable steps.\n",
      "\n",
      "2. Find what motivates you: Identify your personal strengths and pursue activities that bring you joy.\n",
      "\n",
      "3. Track progress: Use metrics like time spent on tasks or progress toward your goals to stay focused.\n",
      "\n",
      "4. Connect with others: Social support networks can increase motivation and provide accountability.\n",
      "\n",
      "5. Reward yourself: Treat yourself to something you enjoy after specific milestones or achievements.\n",
      "\n",
      "6. Eliminate distractions: Turn off notifications during focused work sessions.\n",
      "\n",
      "7. Practice self-care: Engage in activities that promote relax\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Switch model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to generate responses\n",
    "def generate_response(instruction, max_tokens=150):\n",
    "    # Format instruction\n",
    "    messages = [{\"role\": \"user\", \"content\": instruction}]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length\n",
    "    ).to(model.device)\n",
    "    \n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode and extract assistant's response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    if \"assistant\" in response:\n",
    "        assistant_start = response.find(\"assistant\") + len(\"assistant\")\n",
    "        return response[assistant_start:].strip()\n",
    "    return response.strip()\n",
    "\n",
    "# Test questions\n",
    "test_instructions = [\n",
    "    \"How do I make a good first impression?\",\n",
    "    \"Explain what DNA is to a child.\",\n",
    "    \"Give tips for staying motivated.\"\n",
    "]\n",
    "\n",
    "\n",
    "print(\"Testing the trained model:\\n\")\n",
    "print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "for instruction in test_instructions:\n",
    "    print(f\"Q: {instruction}\")\n",
    "    response = generate_response(instruction)\n",
    "    print(f\"A: {response}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnZnOjHE3WAZ"
   },
   "source": [
    "## Summary\n",
    "\n",
    "**What We Did:**\n",
    "1. Created a dataset with multiple responses per question (some accepted, some rejected)\n",
    "2. Filtered to keep ONLY accepted (good) responses\n",
    "3. Fine-tuned TinyLlama using LoRA (efficient training)\n",
    "4. Tested the model on new questions\n",
    "\n",
    "**Key Takeaways:**\n",
    "- **SFT** (Supervised Fine-Tuning) learns from good examples only\n",
    "- Rejected examples are NOT used in SFT training\n",
    "- This approach teaches the model \"what good responses look like\"\n",
    "- For learning from good vs bad comparisons, use DPO instead\n",
    "\n",
    "**Next Steps:**\n",
    "- Try DPO (Direct Preference Optimization) to learn from accepted/rejected pairs\n",
    "- See `DPO_prefs.ipynb` for that approach"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNHAjHzSHgLGy4gsJjSctt1",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10a365e1e883499ab23cc7d9b639adb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17f0dd3348e14f9aaefbbc9a27363b48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f552945661943529cb665cf211e659c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10a365e1e883499ab23cc7d9b639adb6",
      "placeholder": "​",
      "style": "IPY_MODEL_75122a9707544360b04bd3c9596d1837",
      "value": "Truncating train dataset: 100%"
     }
    },
    "24b8e34e1e704d33866bfd8c0e03ae77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "256000d4e6074d279bf3c2ea5f0a38c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2570369609e24de7a00f2fecc73c4dd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d62f4da090a4c6cbe658f232d7737c9",
       "IPY_MODEL_fb9c4a6d51334229a6b84f0279183d1b",
       "IPY_MODEL_edad7a92c5c9479d97d3fffb81e15732"
      ],
      "layout": "IPY_MODEL_2706a6114e894ef69d809ba8aafa0a87"
     }
    },
    "26aad99469e44acf8f8e23237d8b3c27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2706a6114e894ef69d809ba8aafa0a87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "368e1dd8fe7b4fbb84d8773f4870d817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d971d513082457daa995b88f8426b67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52364866254e400fac347c8e75524128": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59db73cff5e045a5b21fbd9c2371e1d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e44d001042a6468181aacd9b6ff8dd77",
      "placeholder": "​",
      "style": "IPY_MODEL_a6a02b2d2a4c48228c5ca98cf02d778c",
      "value": " 80/80 [00:00&lt;00:00, 6592.36 examples/s]"
     }
    },
    "5ee046befcb846eeb688c89173b36dc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5eee9d4b99264c7b98b5d78094abce8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "649d008043e44b5bacec72411f27de22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "693fb29a51a6487fac68328fcc9138ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fd56890138c475f958ca31afdfb897a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a887fa901ce449e49d214b75183f1f6a",
      "max": 80,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_913c04cf88084e89bcc42e509c6892c1",
      "value": 80
     }
    },
    "75122a9707544360b04bd3c9596d1837": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d6a67c8197841f09795ce3a6b7359e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_649d008043e44b5bacec72411f27de22",
      "placeholder": "​",
      "style": "IPY_MODEL_ae0c23f370db43358eda4860e7684512",
      "value": "Adding EOS to train dataset: 100%"
     }
    },
    "7ddacb75e23a48aba945dfea791c39c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d166381b69fc46e29b70714cddfe3448",
      "placeholder": "​",
      "style": "IPY_MODEL_24b8e34e1e704d33866bfd8c0e03ae77",
      "value": "Tokenizing train dataset: 100%"
     }
    },
    "7e89cf2ccc9f41f5a6c1a254cf0190f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bd2cbb574474968888fd6d462677b80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9062fe4e3f2342d68e6c6e9ba7706da1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d6a67c8197841f09795ce3a6b7359e6",
       "IPY_MODEL_954a57e6e67a4d11a25f114ee6eb27d9",
       "IPY_MODEL_a6990773569a4db9bad3509fac8ddc16"
      ],
      "layout": "IPY_MODEL_17f0dd3348e14f9aaefbbc9a27363b48"
     }
    },
    "913c04cf88084e89bcc42e509c6892c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "948abb7b38824b57960c69dfd928ba7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "954a57e6e67a4d11a25f114ee6eb27d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_948abb7b38824b57960c69dfd928ba7c",
      "max": 80,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2bb793078094f1d8fc11aa5e4a9dda1",
      "value": 80
     }
    },
    "98cb1e3db5bd45b2884857a058610dbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5eee9d4b99264c7b98b5d78094abce8f",
      "max": 80,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d971d513082457daa995b88f8426b67",
      "value": 80
     }
    },
    "9d62f4da090a4c6cbe658f232d7737c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5935da2e2da4706ba1ef9cbac5178e0",
      "placeholder": "​",
      "style": "IPY_MODEL_8bd2cbb574474968888fd6d462677b80",
      "value": "Map: 100%"
     }
    },
    "9f28ee892b224c27a0f8655f45fe4085": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4a89ff0807a4dd1b5b615c762a518e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6990773569a4db9bad3509fac8ddc16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e89cf2ccc9f41f5a6c1a254cf0190f2",
      "placeholder": "​",
      "style": "IPY_MODEL_368e1dd8fe7b4fbb84d8773f4870d817",
      "value": " 80/80 [00:00&lt;00:00, 2657.21 examples/s]"
     }
    },
    "a6a02b2d2a4c48228c5ca98cf02d778c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a887fa901ce449e49d214b75183f1f6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae0c23f370db43358eda4860e7684512": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae12386a9fce40808c20cdd436bfe031": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f28ee892b224c27a0f8655f45fe4085",
      "placeholder": "​",
      "style": "IPY_MODEL_a4a89ff0807a4dd1b5b615c762a518e8",
      "value": " 80/80 [00:00&lt;00:00, 1366.06 examples/s]"
     }
    },
    "b5935da2e2da4706ba1ef9cbac5178e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb13a1c56bd14d53a7d26e421e27c7bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ddacb75e23a48aba945dfea791c39c5",
       "IPY_MODEL_6fd56890138c475f958ca31afdfb897a",
       "IPY_MODEL_ae12386a9fce40808c20cdd436bfe031"
      ],
      "layout": "IPY_MODEL_52364866254e400fac347c8e75524128"
     }
    },
    "bc7a69e21bcd43e580c9a6e78fdfd172": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f552945661943529cb665cf211e659c",
       "IPY_MODEL_98cb1e3db5bd45b2884857a058610dbc",
       "IPY_MODEL_59db73cff5e045a5b21fbd9c2371e1d0"
      ],
      "layout": "IPY_MODEL_256000d4e6074d279bf3c2ea5f0a38c0"
     }
    },
    "d166381b69fc46e29b70714cddfe3448": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e44d001042a6468181aacd9b6ff8dd77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4582a33049b4cfeac2e2d44b8d77918": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edad7a92c5c9479d97d3fffb81e15732": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26aad99469e44acf8f8e23237d8b3c27",
      "placeholder": "​",
      "style": "IPY_MODEL_693fb29a51a6487fac68328fcc9138ab",
      "value": " 80/80 [00:00&lt;00:00, 2961.87 examples/s]"
     }
    },
    "f2bb793078094f1d8fc11aa5e4a9dda1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fb9c4a6d51334229a6b84f0279183d1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4582a33049b4cfeac2e2d44b8d77918",
      "max": 80,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ee046befcb846eeb688c89173b36dc3",
      "value": 80
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
